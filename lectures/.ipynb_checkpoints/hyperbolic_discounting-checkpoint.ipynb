{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import respy as rp\n",
    "import yaml\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.iolib.summary2 import summary_col"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The last decade has seen a growing interest in integrating models of hyperbolic discounting within the DCDP framework. Many of these attempts have been concerned with assessing the relevance of behavioral responses and utility losses due to time-inconsistent preferences, typically benchmarked against the exponential discounting model, for the evaluation of social policies. However, **testing the exponential versus the hyperbolic model can be problematic**, as the actions of time-consistent and time-inconsistent agents can be observationally equivalent, especially when commitment devices are not available."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Theoretical results on identification with quasi-hyperbolic discounting formalize the intuition that time preferences can be recovered comparing the behavior of agents that only differ in their \"futures\", where future in this context usually refers to the evolution of the state space. If agents are otherwise identical, differences in their behavior are solely determined by how they discount the utility stream from future periods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Identification strategy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Simulating the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'specs/params_hyp.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-d66cbe0f2168>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# load params\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mparams\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"specs/params_hyp.csv\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msep\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\";\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindex_col\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"category\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"name\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparams\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"value\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# load options\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\respy\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, dialect, error_bad_lines, warn_bad_lines, delim_whitespace, low_memory, memory_map, float_precision)\u001b[0m\n\u001b[0;32m    684\u001b[0m     )\n\u001b[0;32m    685\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 686\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    687\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\respy\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;31m# Create the parser.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 452\u001b[1;33m     \u001b[0mparser\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfp_or_buf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    453\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    454\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\respy\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m    934\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"has_index_names\"\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 936\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    937\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\respy\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[1;34m(self, engine)\u001b[0m\n\u001b[0;32m   1166\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_make_engine\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mengine\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"c\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1167\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"c\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1168\u001b[1;33m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mCParserWrapper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptions\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1169\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1170\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mengine\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m\"python\"\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mC:\\ProgramData\\Anaconda3\\envs\\respy\\lib\\site-packages\\pandas\\io\\parsers.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m   1996\u001b[0m         \u001b[0mkwds\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"usecols\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0musecols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1997\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1998\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mparsers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTextReader\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1999\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_reader\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munnamed_cols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2000\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;32mpandas\\_libs\\parsers.pyx\u001b[0m in \u001b[0;36mpandas._libs.parsers.TextReader._setup_parser_source\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'specs/params_hyp.csv'"
     ]
    }
   ],
   "source": [
    "# load params\n",
    "params = pd.read_csv(\"specs/params_hyp.csv\", sep=\";\", index_col=[\"category\", \"name\"])\n",
    "params[\"value\"] = params[\"value\"].astype(float)\n",
    "\n",
    "# load options\n",
    "with open(ppj(\"specs/options_hyp.yaml\")) as options:\n",
    "    options = yaml.safe_load(options)\n",
    "\n",
    "# change seeds to simulated \"observed\" data\n",
    "options[\"solution_seed\"] = 0\n",
    "options[\"simulation_seed\"] = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simulate = rp.get_simulate_func(params, options)\n",
    "df = simulate(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_choice_probabilities(df, policyDict, colorDict, labelDict):\n",
    "    \"\"\"Plot choice probabilities, comparing behavior of restricted and\n",
    "    unrestricted agents.\n",
    "\n",
    "    Args:\n",
    "        df (pd.DataFrame): Dataframe with choice probabilities.\n",
    "        policyDict (dict): Dictionary, from policies to labels.\n",
    "        colorDict (dict): Dictionary, from choices to colors.\n",
    "        labelDict (dict): Dictionary, from choices to labels.\n",
    "\n",
    "    Return:\n",
    "        Matplotlib figure.\n",
    "\n",
    "    \"\"\"\n",
    "    sns.set_context(\"paper\", font_scale=2)\n",
    "    sns.set_style(\"white\")\n",
    "    fig = plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # policies\n",
    "    policies = list(policyDict.keys())\n",
    "    n_policies = len(policies)\n",
    "\n",
    "    # specify grid\n",
    "    height_ratios = [1 / n_policies] * n_policies\n",
    "    gs = fig.add_gridspec(\n",
    "        n_policies, 2, height_ratios=height_ratios, width_ratios=[0.5, 1]\n",
    "    )\n",
    "\n",
    "    # conditional choices axis\n",
    "    axs = [fig.add_subplot(gs[i, 0]) for i in range(0, n_policies)]\n",
    "\n",
    "    # unconditional choices axis\n",
    "    ax_main = fig.add_subplot(gs[0:, 1:2])\n",
    "\n",
    "    for ax, policy in zip(axs, policies):\n",
    "\n",
    "        df.query(\"Policy == @policy\").groupby(\"Period\").Choice.value_counts(\n",
    "            normalize=True\n",
    "        ).unstack().plot.bar(\n",
    "            stacked=True, rot=0, legend=False, width=1.0, color=colorDict, ax=ax\n",
    "        )\n",
    "\n",
    "        # decluttering\n",
    "        ax.xaxis.label.set_visible(False)\n",
    "        ax.yaxis.label.set_visible(False)\n",
    "        ax.xaxis.set_ticks([])\n",
    "        ax.yaxis.set_ticks([])\n",
    "\n",
    "        # set policy name\n",
    "        ax.set_title(\n",
    "            policyDict[policy], pad=20, x=-0.095, y=0, weight=\"bold\", fontsize=16\n",
    "        )\n",
    "\n",
    "        # set dashed line at t = 4, where agents are restricted\n",
    "        if policy == \"restricted\":\n",
    "            ax.axvline(x=3.5, color=\"black\", linestyle=\"dashed\", linewidth=2)\n",
    "        if policy == \"veryrestricted\":\n",
    "            ax.axvline(x=3.5, color=\"black\", linestyle=\"dashed\", linewidth=2)\n",
    "            ax.axvline(x=1.5, color=\"black\", linestyle=\"dashed\", linewidth=2)\n",
    "\n",
    "    plt.suptitle(\"Conditional Choice Probabilities\", x=0.255, y=1.07, fontsize=18)\n",
    "\n",
    "    # main axis (unconditional choice probabilities)\n",
    "    df.groupby(\"Period\").Choice.value_counts(normalize=True).unstack().plot.bar(\n",
    "        stacked=True, rot=90, legend=False, color=colorDict, width=0.75, ax=ax_main,\n",
    "    )\n",
    "    ax_main.yaxis.tick_right()\n",
    "    ax_main.tick_params(right=False, bottom=False)\n",
    "    ax_main.set_title(\"Unconditional Choice Probabilities\", y=1.18, fontsize=18)\n",
    "    ax_main.set_xlabel(\"Period\", x=0.96, labelpad=20, fontsize=18)\n",
    "\n",
    "    # legend\n",
    "    labels = list(labelDict.values())\n",
    "    plt.legend(\n",
    "        loc=\"lower center\",\n",
    "        bbox_to_anchor=(0, -0.3),\n",
    "        ncol=len(labels),\n",
    "        labels=labels,\n",
    "        frameon=False,\n",
    "    )\n",
    "\n",
    "    # annotate time preference parameter\n",
    "    delta = df[\"Discount_Rate\"][0][0]\n",
    "    beta = df[\"Present_Bias\"][0][0]\n",
    "    plt.gcf().text(\n",
    "        0.125, 0.915, f\"δ = {delta}, β = {beta}\", fontstyle=\"oblique\", fontsize=18\n",
    "    )\n",
    "\n",
    "    fig.subplots_adjust(wspace=0.025, hspace=0.05)\n",
    "\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_choice_probabilities(\n",
    "    df=df, \n",
    "    policyDict={\"unrestricted\": \"Unr\", \"restricted\": \"R\", \"veryrestricted\": \"VR\"},\n",
    "    colorDict={\"a\": \"#eb760a\", \"b\": \"#43aa8b\", \"edu\": \"#f9c74f\", \"home\": \"#577590\"},\n",
    "    labelDict={\"a\": \"Occ. A\", \"b\": \"Occ. B\", \"edu\": \"Education\", \"home\": \"Home\"},\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assessing the validity of the choice restrictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Choice restrictions need to be salient to the decision-making process of the agents, a requirement which is addressed by a precise rank condition in theoretical results and by economically-motivated analysis in empirical applications. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In \\textcite{Haan2020} exogenous variation in the length of job protection for working mothers provides observable state variables that matter for choice, without directly entering the per-period utility function. The authors show that women who enjoyed longer period of job protection took significantly longer career breaks than those who didn't, which is taken as evidence of the policies being salient. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the two revisited version of \\textcite{KeaneWolpin1994}, the choice restrictions should influence the agents' educational decisions, particularly at the beginning of the life-cycle. Therefore, it is natural to check whether being exposed to increasingly more restrictive policy raises, on average, the agents' years of education. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_restricted = df.query(\"Period == 0\")\n",
    "\n",
    "restrictions = [np.where(df_restricted[\"Policy\"] == pol, 1, 0) for policy in [\"restricted\", \"veryrestricted\"]]\n",
    "restrictions = np.column_stack(tuple(restrictions))\n",
    "restrictions = sm.add_constant(restrictions)\n",
    "\n",
    "dep_vars = [\n",
    "    df.query(\"Period == @period\")[\"Experience_Edu\"] for period in [9, 39]\n",
    "]\n",
    "\n",
    "fitted_models = [\n",
    "    sm.OLS(endog=var, exog=restriction, missing=\"drop\").fit(cov_type=\"HC1\")\n",
    "    for var in dep_vars\n",
    "]\n",
    "\n",
    "for i, fitted_model in enumerate(fitted_models):\n",
    "        regDict[i] = namedtuplee(\n",
    "            params=et._extract_params_from_sm(fitted_model),\n",
    "            info={**et._extract_info_from_sm(fitted_model)},\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_tex = et.estimation_table(\n",
    "        [regDict[0], regDict[1]],\n",
    "        return_type=\"latex\",\n",
    "        custom_model_names={\n",
    "            r\"Years of education ($t=10$)\": [0],\n",
    "            r\"Years of education ($t=40$)\": [1],\n",
    "        },\n",
    "        #custom_col_names=[\"Exponential\", \"Hyperbolic\", \"Exponential\", \"Hyperbolic\"],\n",
    "        custom_param_names={\n",
    "            0: \"Restriction\",\n",
    "            \"x1\": \"Restriction\",\n",
    "            \"x2\": \"Double restriction\",\n",
    "            \"const\": \"Intercept\",\n",
    "        },\n",
    "        left_decimals=4,\n",
    "        alignment_warning=False,\n",
    "        siunitx_warning=False,\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Practical identification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Counterfactual predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
